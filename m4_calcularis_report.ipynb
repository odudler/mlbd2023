{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8af48ca1-b6d1-4092-b7b5-037d3c2d7aef",
   "metadata": {
    "id": "8af48ca1-b6d1-4092-b7b5-037d3c2d7aef"
   },
   "source": [
    "# M4 | Research Investigation Notebook\n",
    "\n",
    "In this notebook, you will do a research investigation of your chosen dataset in teams. You will begin by formally selecting your research question (task 0), then processing your data (task 1), creating a predictive model (task 2), evaluating your model's results (task 3), and describing the contributions of each team member (task 4).\n",
    "\n",
    "For grading, please make sure your notebook has all cells run and is stored in your team's [Github Classroom repository](https://classroom.github.com/a/CNxME27U). You will also need to write a short, 2 page report about your design decisions as a team, to be stored in your repository. The Milestone 4 submission will be the contents of your repository at the due date (April 28 at 23:59 CET).\n",
    "\n",
    "## Brief overview of Calcularis\n",
    "[Calcularis](https://school.alemira.com/de/calcularis/) by Alemira School is a mathematics learning program developed with neuroscientists and computer scientists from ETH Zurich. It promotes the development and interaction of the different areas of the brain that are responsible for processing numbers and quantities and solving mathematical tasks. Calcularis can be used from 1st grade to high school. Children with dyscalculia also benefit in the long term and overcome their arithmetic weakness.\n",
    "\n",
    "The Calcularis dataset has three main tables:\n",
    "* ***users***: meta information about users (i.e. total time spent learning with Calcularis, geographic location).\n",
    "* ***events***: events done by the users in the platform (i.e. playing a game, selecting a new animal in the zoo simulation).\n",
    "* ***subtasks***: sub-tasks with answer attempts solved by users, primarily in the context of game events.\n",
    "\n",
    "These tables and useful metadata information are described in detail in the [Milestone 2 data exploration notebook](https://github.com/epfl-ml4ed/mlbd-2023/blob/main/project/milestone-02/m2_calcularis_sciper.ipynb).\n",
    "\n",
    "We have provided access to the [full dataset](https://moodle.epfl.ch/mod/forum/discuss.php?d=88179) (~65k users) and a randomly selected subset (~1k users from M2). We have also provided access to a [test account to experiment with Calcularis](https://moodle.epfl.ch/mod/forum/discuss.php?d=88094). You should provide arguments and justifications for all of your design decisions throughout this investigation. You can use your M3 responses as the basis for this discussion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82ea2d32-f0a9-4dc9-bb60-be43399f5b89",
   "metadata": {
    "id": "82ea2d32-f0a9-4dc9-bb60-be43399f5b89"
   },
   "outputs": [],
   "source": [
    "# Import the tables of the data set as dataframes.\n",
    "import time\n",
    "start = time.time()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATA_DIR = './../data' # You many change the directory\n",
    "\n",
    "# You can use the nrows=X argument in pd.read_csv to truncate your data\n",
    "users_small = pd.read_csv('{}/calcularis_small_users.csv'.format(DATA_DIR), index_col=0)\n",
    "events_small = pd.read_csv('{}/calcularis_small_events.csv'.format(DATA_DIR), index_col=0)\n",
    "subtasks_small = pd.read_csv('{}/calcularis_small_subtasks.csv'.format(DATA_DIR), index_col=0)\n",
    "users_full = pd.read_csv(f'{DATA_DIR}/full_calcularis_users.csv', index_col=0)\n",
    "events_full = pd.read_csv(f'{DATA_DIR}/full_calcularis_events.csv', index_col=0)\n",
    "subtasks_full = pd.read_csv(f'{DATA_DIR}/full_calcularis_subtasks.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c7eecd",
   "metadata": {},
   "source": [
    "## Task 0: Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1c9055",
   "metadata": {},
   "source": [
    "**Research question:**\n",
    "For this milestone we focus on detecting wheel-spinning behaviour of Calcularis Users. This is a time series analysis. We rely on features that were proven to be useful in various scientific papers which had to goal of detecting wheel-spinning on different datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77f62b0-1945-48f1-8f22-5f6ebda1db8e",
   "metadata": {
    "id": "a77f62b0-1945-48f1-8f22-5f6ebda1db8e"
   },
   "source": [
    "## Task 1: Data Preprocessing\n",
    "\n",
    "In this section, you are asked to preprocess your data in a way that is relevant for the model. Please include 1-2 visualizations of features / data explorations that are related to your downstream prediction task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77fcfe93-e999-4df7-934d-35db62ef3ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess given data frames (clean out data)\n",
    "\n",
    "#remove event entries which have 0 subtasks\n",
    "events_full = events_full[(events_full.subtasks != \"[]\") & ~events_full.subtasks.isna()]\n",
    "\n",
    "#remove event/subtasks entries which have no start value, no skill_id, no correct value\n",
    "subtasks_full = subtasks_full[~subtasks_full.correct.isna()]\n",
    "events_full = events_full[~events_full.start.isna() & ~events_full.skill_id.isna()]\n",
    "\n",
    "#events_full[events_full['subtasks'] == '[]'].head()\n",
    "#events_full['num_subtasks'] = subtasks_full.groupby(['event_id']).size()\n",
    "#print(events_full['num_subtasks'].unique())\n",
    "#print(events_full[events_full.num_subtasks.isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34cefd0d-4f8a-4227-8fb4-f30521abf78d",
   "metadata": {
    "id": "34cefd0d-4f8a-4227-8fb4-f30521abf78d"
   },
   "outputs": [],
   "source": [
    "# Your code for data processing goes here\n",
    "events = events_small\n",
    "\n",
    "subtasks = subtasks_small\n",
    "processed_df = events.copy()\n",
    "processed_df.drop_duplicates(inplace=True)\n",
    "processed_df = processed_df[processed_df.type == 'task']\n",
    "processed_df = processed_df[['user_id', 'skill_id', 'learning_time_ms', 'start']]\n",
    "processed_df = processed_df.reset_index()\n",
    "processed_df['correct'] = processed_df.apply(\n",
    "    lambda row: subtasks[subtasks.event_id == row.event_id].iloc[0].correct, axis=1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cda1cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>skill_id</th>\n",
       "      <th>learning_time_ms</th>\n",
       "      <th>start</th>\n",
       "      <th>correct</th>\n",
       "      <th>po</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8835.0</td>\n",
       "      <td>2022-11-02T08:39:12.355Z</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>21167.0</td>\n",
       "      <td>2022-11-11T10:26:27.893Z</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11182.0</td>\n",
       "      <td>2022-11-18T10:34:01.044Z</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6823.0</td>\n",
       "      <td>2022-11-25T10:32:43.428Z</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9107.0</td>\n",
       "      <td>2022-12-02T10:44:40.555Z</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33654</th>\n",
       "      <td>37414</td>\n",
       "      <td>998</td>\n",
       "      <td>110.0</td>\n",
       "      <td>7635.0</td>\n",
       "      <td>2020-12-02T11:57:00.179Z</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33655</th>\n",
       "      <td>37415</td>\n",
       "      <td>998</td>\n",
       "      <td>111.0</td>\n",
       "      <td>7762.0</td>\n",
       "      <td>2021-01-06T14:14:36.824Z</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33656</th>\n",
       "      <td>37417</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9514.0</td>\n",
       "      <td>2019-09-30T10:04:31.264Z</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33657</th>\n",
       "      <td>37418</td>\n",
       "      <td>1000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>96077.0</td>\n",
       "      <td>2020-01-20T10:02:02.957Z</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33658</th>\n",
       "      <td>37419</td>\n",
       "      <td>1000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23250.0</td>\n",
       "      <td>2020-02-24T10:06:08.921Z</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33659 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       event_id  user_id  skill_id  learning_time_ms  \\\n",
       "0             0        1       1.0            8835.0   \n",
       "1             1        1       4.0           21167.0   \n",
       "2             2        1       7.0           11182.0   \n",
       "3             3        1      19.0            6823.0   \n",
       "4             4        1       7.0            9107.0   \n",
       "...         ...      ...       ...               ...   \n",
       "33654     37414      998     110.0            7635.0   \n",
       "33655     37415      998     111.0            7762.0   \n",
       "33656     37417     1000       1.0            9514.0   \n",
       "33657     37418     1000       3.0           96077.0   \n",
       "33658     37419     1000       3.0           23250.0   \n",
       "\n",
       "                          start  correct  po  \n",
       "0      2022-11-02T08:39:12.355Z     True   1  \n",
       "1      2022-11-11T10:26:27.893Z     True   1  \n",
       "2      2022-11-18T10:34:01.044Z     True   1  \n",
       "3      2022-11-25T10:32:43.428Z    False   1  \n",
       "4      2022-12-02T10:44:40.555Z     True   2  \n",
       "...                         ...      ...  ..  \n",
       "33654  2020-12-02T11:57:00.179Z     True   1  \n",
       "33655  2021-01-06T14:14:36.824Z     True   2  \n",
       "33656  2019-09-30T10:04:31.264Z    False   1  \n",
       "33657  2020-01-20T10:02:02.957Z     True   1  \n",
       "33658  2020-02-24T10:06:08.921Z     True   2  \n",
       "\n",
       "[33659 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df['po'] = processed_df.apply(\n",
    "    lambda row: processed_df[(processed_df.user_id == row.user_id) & (processed_df.skill_id == row.skill_id) & (processed_df.start <= row.start)]['event_id'].count(),\n",
    "    axis=1\n",
    ")\n",
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7eeefcd",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Does not include result from the current practice opportunity\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m processed_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcorrect_response_count\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mprocessed_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessed_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocessed_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocessed_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mskill_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mskill_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocessed_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcorrect\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m processed_df\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/frame.py:9568\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9557\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m   9559\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m   9560\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   9561\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9566\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m   9567\u001b[0m )\n\u001b[0;32m-> 9568\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/apply.py:764\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[0;32m--> 764\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/apply.py:891\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 891\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    893\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/apply.py:907\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m    906\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 907\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    908\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    909\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    910\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    911\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Does not include result from the current practice opportunity\u001b[39;00m\n\u001b[1;32m      2\u001b[0m processed_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcorrect_response_count\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m processed_df\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m row: processed_df[(processed_df\u001b[38;5;241m.\u001b[39muser_id \u001b[38;5;241m==\u001b[39m row\u001b[38;5;241m.\u001b[39muser_id) \u001b[38;5;241m&\u001b[39m (processed_df\u001b[38;5;241m.\u001b[39mskill_id \u001b[38;5;241m==\u001b[39m row\u001b[38;5;241m.\u001b[39mskill_id) \u001b[38;5;241m&\u001b[39m (\u001b[43mprocessed_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m)][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcorrect\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum(),\n\u001b[1;32m      4\u001b[0m     axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m processed_df\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/ops/common.py:72\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     70\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/arraylike.py:50\u001b[0m, in \u001b[0;36mOpsMixin.__lt__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__lt__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__lt__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/series.py:6243\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6240\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   6242\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 6243\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6245\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:287\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_object_dtype(lvalues\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 287\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mcomp_method_OBJECT_ARRAY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    290\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:75\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m     73\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mvec_compare(x\u001b[38;5;241m.\u001b[39mravel(), y\u001b[38;5;241m.\u001b[39mravel(), op)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 75\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mlibops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscalar_compare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Does not include result from the current practice opportunity\n",
    "processed_df['correct_response_count'] = processed_df.apply(\n",
    "    lambda row: processed_df[(processed_df.user_id == row.user_id) & (processed_df.skill_id == row.skill_id) & (processed_df.start < row.start)]['correct'].sum(),\n",
    "    axis=1\n",
    ")\n",
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dff3550",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df['correct_response_percentage'] = processed_df.apply(\n",
    "    lambda row: row.correct_response_count / (row.po - 1) if row.po > 1 else 0,\n",
    "    axis=1\n",
    ")\n",
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f432a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df[(processed_df.user_id == 41) & (processed_df.skill_id == 95)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71072548",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df = processed_df.sort_values(by='po')\n",
    "for index, row in processed_df.iterrows():\n",
    "    if row.po == 1:\n",
    "        processed_df.loc[index, 'correct_response_in_a_row_count'] = 0\n",
    "    else:\n",
    "        \n",
    "        last_response = processed_df[(\n",
    "            processed_df.user_id == row.user_id) & (processed_df.skill_id == row.skill_id) & (\n",
    "            processed_df.po == row.po-1\n",
    "        )]\n",
    "        processed_df.loc[index, 'correct_response_in_a_row_count'] = last_response.correct_response_in_a_row_count.values[0] + 1 if last_response.correct.values[0] else 0\n",
    "\n",
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd78974",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df['correct_response_in_a_row_percentage'] = processed_df.apply(\n",
    "    lambda row: row.correct_response_in_a_row_count / (row.po - 1) if row.po > 1 else 0,\n",
    "    axis=1\n",
    ")\n",
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c75d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df['time_on_current_skill_ms'] = processed_df.apply(\n",
    "    lambda row: processed_df[\n",
    "        (processed_df.user_id == row.user_id) &\n",
    "        (processed_df.skill_id == row.skill_id) & \n",
    "        (processed_df.start <= row.start)\n",
    "    ]['learning_time_ms'].sum(),\n",
    "    axis=1\n",
    ")\n",
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419e16ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "PO_CUTOFF = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5728c7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "before = processed_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6393f513",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df = before[before.po <= PO_CUTOFF]\n",
    "print((len(before)-len(processed_df))/len(before))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ad0326",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df['pessimistic_wheelspinning'] = processed_df.apply(\n",
    "    lambda row: len(processed_df[\n",
    "        (processed_df.user_id == row.user_id) & \n",
    "        (processed_df.skill_id == row.skill_id) & \n",
    "        (processed_df.correct_response_in_a_row_count >= 3)\n",
    "    ]) == 0,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9374f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_with_sufficient_po = processed_df[processed_df.po == PO_CUTOFF].user_id.unique()\n",
    "processed_df['optimistic_wheelspinning'] = processed_df.user_id.isin(users_with_sufficient_po) & processed_df.pessimistic_wheelspinning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d684df",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df.drop(columns=[\n",
    "    'event_id', 'learning_time_ms', 'start', 'correct'\n",
    "], inplace=True)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445ffd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "backup_df = processed_df.copy()\n",
    "temp_df = processed_df[processed_df.correct_response_in_a_row_count == 3]\n",
    "mastery_achieved = pd.DataFrame(temp_df.groupby(['user_id', 'skill_id'])['po'].min())\n",
    "\n",
    "for index, row in processed_df.iterrows():\n",
    "    if (\n",
    "        ((row.user_id, row.skill_id) in mastery_achieved.index) and\n",
    "        row.po >= mastery_achieved.loc[(row.user_id, row.skill_id)].po\n",
    "    ):\n",
    "        processed_df.drop(index=index, inplace=True)\n",
    "\n",
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e54258",
   "metadata": {},
   "outputs": [],
   "source": [
    "backup_df[backup_df.user_id == 865]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6f971b",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df[(processed_df.user_id == 865) & (processed_df.skill_id == 48)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99491615",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_indeterminate_df = processed_df[processed_df.optimistic_wheelspinning == processed_df.pessimistic_wheelspinning]\n",
    "no_indeterminate_df.rename(columns={'pessimistic_wheelspinning': 'is_wheelspinning'}, inplace=True)\n",
    "no_indeterminate_df.drop(columns='optimistic_wheelspinning', inplace=True)\n",
    "no_indeterminate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7958773",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(processed_df))\n",
    "print(len(no_indeterminate_df))\n",
    "\n",
    "len(no_indeterminate_df.groupby(['user_id', 'skill_id']).count()) / len(processed_df.groupby(['user_id', 'skill_id']).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f26b56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((no_indeterminate_df.user_id.nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d0fcca-686e-47a3-8567-c3f92db187d4",
   "metadata": {
    "id": "76d0fcca-686e-47a3-8567-c3f92db187d4"
   },
   "source": [
    "*Your discussion about your processing decisions goes here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85633adb-d317-4ee3-bf06-e9f82f589c41",
   "metadata": {
    "id": "85633adb-d317-4ee3-bf06-e9f82f589c41"
   },
   "source": [
    "## Task 2: Model Building\n",
    "\n",
    "Train a model for your research question. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b65ebd-c148-4ae8-833e-018411eeda86",
   "metadata": {
    "id": "90b65ebd-c148-4ae8-833e-018411eeda86"
   },
   "outputs": [],
   "source": [
    "# Your code for training a model goes here\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_auc_score, balanced_accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler, normalize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# label_df = pd.DataFrame(no_indeterminate_df.groupby(['user_id','skill_id'])['is_wheelspinning'].unique())\n",
    "# label_df['is_wheelspinning'] = label_df.apply(\n",
    "#     lambda row: row.is_wheelspinning[0],\n",
    "#     axis=1\n",
    "# )\n",
    "# training_df = no_indeterminate_df.drop(columns=['is_wheelspinning'])\n",
    "training_df = no_indeterminate_df.copy()\n",
    "datasets = {}\n",
    "models = {}\n",
    "results = {}\n",
    "\n",
    "def compute_scores(clf, X_train, y_train, X_test, y_test, roundnum=3):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "    y_pred_proba = clf.predict_proba(X_test)[:,1]\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    return round(accuracy, roundnum), round(auc, roundnum)\n",
    "\n",
    "\n",
    "\n",
    "for po in range(2, PO_CUTOFF+1):\n",
    "    dataset = training_df[no_indeterminate_df.po < po]\n",
    "    users = dataset.user_id.unique()\n",
    "    users_train, users_val = train_test_split(users, test_size=0.2, random_state=0)\n",
    "    \n",
    "    X_train = dataset[dataset.user_id.isin(users_train)]\n",
    "    X_val = dataset[dataset.user_id.isin(users_val)]\n",
    "    y_train = X_train.is_wheelspinning\n",
    "    X_train.drop(columns='is_wheelspinning', inplace=True)\n",
    "    y_val = X_val.is_wheelspinning\n",
    "    X_val.drop(columns='is_wheelspinning', inplace=True)\n",
    "    datasets[po] = (X_train, X_val, y_train, y_val)\n",
    "    models[po] = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=5,\n",
    "        random_state=0,\n",
    "        criterion='entropy'\n",
    "    )\n",
    "    results[po] = compute_scores(\n",
    "        models[po], X_train, y_train, X_val, y_val\n",
    "    )\n",
    "    print(f'For practice opportunity {po}, balanced accuracy = {results[po][0]}, AUC={results[po][1]}')\n",
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c88994",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import time\n",
    "dir_name = time.time()\n",
    "os.mkdir(f'./models/{dir_name}_{PO_CUTOFF}')\n",
    "for po in range(2, PO_CUTOFF):\n",
    "    os.mkdir(f'./models/{dir_name}_{PO_CUTOFF}/datasets_{po}')\n",
    "    pickle.dump(datasets[po][0], open(f'./models/{dir_name}_{PO_CUTOFF}/datasets_{po}/x_train.pkl', 'wb'))\n",
    "    pickle.dump(datasets[po][1], open(f'./models/{dir_name}_{PO_CUTOFF}/datasets_{po}/x_val.pkl', 'wb'))\n",
    "    pickle.dump(datasets[po][2], open(f'./models/{dir_name}_{PO_CUTOFF}/datasets_{po}/y_train.pkl', 'wb'))\n",
    "    pickle.dump(datasets[po][3], open(f'./models/{dir_name}_{PO_CUTOFF}/datasets_{po}/y_val.pkl', 'wb'))\n",
    "    pickle.dump(models[po], open(f'./models/{dir_name}_{PO_CUTOFF}/model_{po}.pkl', 'wb'))\n",
    "pickle.dump(results, open(f'./models/{dir_name}_{PO_CUTOFF}/results.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9dd126",
   "metadata": {},
   "source": [
    "*Your discussion about your model training goes here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c9a655-cec9-4c57-aec7-7a982f57a3af",
   "metadata": {
    "id": "b3c9a655-cec9-4c57-aec7-7a982f57a3af"
   },
   "source": [
    "## Task 3: Model Evaluation\n",
    "In this task, you will use metrics to evaluate your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01e838f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for model evaluation goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57e3f3d",
   "metadata": {},
   "source": [
    "*Your discussion/interpretation about your model's behavior goes here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1607d4b3",
   "metadata": {},
   "source": [
    "## Task 4: Team Reflection\n",
    "Please describe the contributions of each team member to Milestone 4. Reflect on how you worked as team: what went well, what can be improved for the next milestone?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3dd783",
   "metadata": {},
   "source": [
    "*Your discussion about team responsibilities goes here*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "m2-classtime-sciper.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "5ae935d15d48ebdb97660a605eaaed321c4390766b1d9f8f679a61125f89d14f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
