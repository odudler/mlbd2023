{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8af48ca1-b6d1-4092-b7b5-037d3c2d7aef",
   "metadata": {
    "id": "8af48ca1-b6d1-4092-b7b5-037d3c2d7aef"
   },
   "source": [
    "# M4 | Research Investigation Notebook\n",
    "\n",
    "In this notebook, you will do a research investigation of your chosen dataset in teams. You will begin by formally selecting your research question (task 0), then processing your data (task 1), creating a predictive model (task 2), evaluating your model's results (task 3), and describing the contributions of each team member (task 4).\n",
    "\n",
    "For grading, please make sure your notebook has all cells run and is stored in your team's [Github Classroom repository](https://classroom.github.com/a/CNxME27U). You will also need to write a short, 2 page report about your design decisions as a team, to be stored in your repository. The Milestone 4 submission will be the contents of your repository at the due date (April 28 at 23:59 CET).\n",
    "\n",
    "## Brief overview of Calcularis\n",
    "[Calcularis](https://school.alemira.com/de/calcularis/) by Alemira School is a mathematics learning program developed with neuroscientists and computer scientists from ETH Zurich. It promotes the development and interaction of the different areas of the brain that are responsible for processing numbers and quantities and solving mathematical tasks. Calcularis can be used from 1st grade to high school. Children with dyscalculia also benefit in the long term and overcome their arithmetic weakness.\n",
    "\n",
    "The Calcularis dataset has three main tables:\n",
    "* ***users***: meta information about users (i.e. total time spent learning with Calcularis, geographic location).\n",
    "* ***events***: events done by the users in the platform (i.e. playing a game, selecting a new animal in the zoo simulation).\n",
    "* ***subtasks***: sub-tasks with answer attempts solved by users, primarily in the context of game events.\n",
    "\n",
    "These tables and useful metadata information are described in detail in the [Milestone 2 data exploration notebook](https://github.com/epfl-ml4ed/mlbd-2023/blob/main/project/milestone-02/m2_calcularis_sciper.ipynb).\n",
    "\n",
    "We have provided access to the [full dataset](https://moodle.epfl.ch/mod/forum/discuss.php?d=88179) (~65k users) and a randomly selected subset (~1k users from M2). We have also provided access to a [test account to experiment with Calcularis](https://moodle.epfl.ch/mod/forum/discuss.php?d=88094). You should provide arguments and justifications for all of your design decisions throughout this investigation. You can use your M3 responses as the basis for this discussion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ea2d32-f0a9-4dc9-bb60-be43399f5b89",
   "metadata": {
    "id": "82ea2d32-f0a9-4dc9-bb60-be43399f5b89"
   },
   "outputs": [],
   "source": [
    "# Import the tables of the data set as dataframes.\n",
    "import time\n",
    "start = time.time()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATA_DIR = './../data' # You many change the directory\n",
    "\n",
    "# You can use the nrows=X argument in pd.read_csv to truncate your data\n",
    "users_small = pd.read_csv('{}/calcularis_small_users.csv'.format(DATA_DIR), index_col=0)\n",
    "events_small = pd.read_csv('{}/calcularis_small_events.csv'.format(DATA_DIR), index_col=0)\n",
    "subtasks_small = pd.read_csv('{}/calcularis_small_subtasks.csv'.format(DATA_DIR), index_col=0)\n",
    "users_full = pd.read_csv(f'{DATA_DIR}/full_calcularis_users.csv', index_col=0)\n",
    "events_full = pd.read_csv(f'{DATA_DIR}/full_calcularis_events.csv', index_col=0)\n",
    "subtasks_full = pd.read_csv(f'{DATA_DIR}/full_calcularis_subtasks.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c7eecd",
   "metadata": {},
   "source": [
    "## Task 0: Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1c9055",
   "metadata": {},
   "source": [
    "**Research question:**\n",
    "For this milestone we focus on detecting wheel-spinning behaviour of Calcularis Users. This is a time series analysis. We rely on features that were proven to be useful in various scientific papers which had to goal of detecting wheel-spinning on different datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77f62b0-1945-48f1-8f22-5f6ebda1db8e",
   "metadata": {
    "id": "a77f62b0-1945-48f1-8f22-5f6ebda1db8e"
   },
   "source": [
    "## Task 1: Data Preprocessing\n",
    "\n",
    "In this section, you are asked to preprocess your data in a way that is relevant for the model. Please include 1-2 visualizations of features / data explorations that are related to your downstream prediction task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fcfe93-e999-4df7-934d-35db62ef3ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess given data frames (clean out data)\n",
    "\n",
    "#remove event entries which have 0 subtasks\n",
    "events_cleaned = events_full[(events_full.subtasks != \"[]\") & ~events_full.subtasks.isna()]\n",
    "\n",
    "#remove event/subtasks entries which have no start value, no skill_id, no correct value\n",
    "subtasks_cleaned = subtasks_full[~subtasks_full.correct.isna()]\n",
    "events_cleaned = events_cleaned[~events_cleaned.start.isna() & ~events_cleaned.skill_id.isna()]\n",
    "\n",
    "#events_full[events_full['subtasks'] == '[]'].head()\n",
    "#events_full['num_subtasks'] = subtasks_full.groupby(['event_id']).size()\n",
    "#print(events_full['num_subtasks'].unique())\n",
    "#print(events_full[events_full.num_subtasks.isna()])\n",
    "\n",
    "print(f\"Small:: Users: {len(users_small)}, Events: {len(events_small)}, Subtasks: {len(subtasks_small)}\")\n",
    "print(f\"Full:: Users: {len(users_full)}, Events: {len(events_full)}, Subtasks: {len(subtasks_full)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34cefd0d-4f8a-4227-8fb4-f30521abf78d",
   "metadata": {
    "id": "34cefd0d-4f8a-4227-8fb4-f30521abf78d"
   },
   "outputs": [],
   "source": [
    "# Your code for data processing goes here\n",
    "events = events_cleaned\n",
    "\n",
    "subtasks = subtasks_cleaned\n",
    "processed_df = events.copy()\n",
    "processed_df.drop_duplicates(inplace=True)\n",
    "processed_df = processed_df[processed_df.type == 'task']\n",
    "processed_df = processed_df[['user_id', 'skill_id', 'learning_time_ms', 'start']]\n",
    "processed_df = processed_df.reset_index()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4493f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df['correct'] = processed_df.apply(\n",
    "    lambda row: subtasks[subtasks.event_id == row.event_id].iloc[0].correct, axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cda1cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df['po'] = processed_df.apply(\n",
    "    lambda row: processed_df[(processed_df.user_id == row.user_id) & (processed_df.skill_id == row.skill_id) & (processed_df.start <= row.start)]['event_id'].count(),\n",
    "    axis=1\n",
    ")\n",
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7eeefcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does not include result from the current practice opportunity\n",
    "processed_df['correct_response_count'] = processed_df.apply(\n",
    "    lambda row: processed_df[(processed_df.user_id == row.user_id) & (processed_df.skill_id == row.skill_id) & (processed_df.start < row.start)]['correct'].sum(),\n",
    "    axis=1\n",
    ")\n",
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dff3550",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df['correct_response_percentage'] = processed_df.apply(\n",
    "    lambda row: row.correct_response_count / (row.po - 1) if row.po > 1 else 0,\n",
    "    axis=1\n",
    ")\n",
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f432a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df[(processed_df.user_id == 41) & (processed_df.skill_id == 95)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71072548",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df = processed_df.sort_values(by='po')\n",
    "for index, row in processed_df.iterrows():\n",
    "    if row.po == 1:\n",
    "        processed_df.loc[index, 'correct_response_in_a_row_count'] = 0\n",
    "    else:\n",
    "        \n",
    "        last_response = processed_df[(\n",
    "            processed_df.user_id == row.user_id) & (processed_df.skill_id == row.skill_id) & (\n",
    "            processed_df.po == row.po-1\n",
    "        )]\n",
    "        processed_df.loc[index, 'correct_response_in_a_row_count'] = last_response.correct_response_in_a_row_count.values[0] + 1 if last_response.correct.values[0] else 0\n",
    "\n",
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd78974",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df['correct_response_in_a_row_percentage'] = processed_df.apply(\n",
    "    lambda row: row.correct_response_in_a_row_count / (row.po - 1) if row.po > 1 else 0,\n",
    "    axis=1\n",
    ")\n",
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c75d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df['time_on_current_skill_ms'] = processed_df.apply(\n",
    "    lambda row: processed_df[\n",
    "        (processed_df.user_id == row.user_id) &\n",
    "        (processed_df.skill_id == row.skill_id) & \n",
    "        (processed_df.start <= row.start)\n",
    "    ]['learning_time_ms'].sum(),\n",
    "    axis=1\n",
    ")\n",
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419e16ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "PO_CUTOFF = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5728c7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "before = processed_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6393f513",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df = before[before.po <= PO_CUTOFF]\n",
    "print((len(before)-len(processed_df))/len(before))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ad0326",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df['pessimistic_wheelspinning'] = processed_df.apply(\n",
    "    lambda row: len(processed_df[\n",
    "        (processed_df.user_id == row.user_id) & \n",
    "        (processed_df.skill_id == row.skill_id) & \n",
    "        (processed_df.correct_response_in_a_row_count >= 3)\n",
    "    ]) == 0,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9374f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_with_sufficient_po = processed_df[processed_df.po == PO_CUTOFF].user_id.unique()\n",
    "processed_df['optimistic_wheelspinning'] = processed_df.user_id.isin(users_with_sufficient_po) & processed_df.pessimistic_wheelspinning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d684df",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df.drop(columns=[\n",
    "    'event_id', 'learning_time_ms', 'start', 'correct'\n",
    "], inplace=True)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445ffd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "backup_df = processed_df.copy()\n",
    "temp_df = processed_df[processed_df.correct_response_in_a_row_count == 3]\n",
    "mastery_achieved = pd.DataFrame(temp_df.groupby(['user_id', 'skill_id'])['po'].min())\n",
    "\n",
    "for index, row in processed_df.iterrows():\n",
    "    if (\n",
    "        ((row.user_id, row.skill_id) in mastery_achieved.index) and\n",
    "        row.po >= mastery_achieved.loc[(row.user_id, row.skill_id)].po\n",
    "    ):\n",
    "        processed_df.drop(index=index, inplace=True)\n",
    "\n",
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e54258",
   "metadata": {},
   "outputs": [],
   "source": [
    "backup_df[backup_df.user_id == 865]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6f971b",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df[(processed_df.user_id == 865) & (processed_df.skill_id == 48)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99491615",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_indeterminate_df = processed_df[processed_df.optimistic_wheelspinning == processed_df.pessimistic_wheelspinning]\n",
    "no_indeterminate_df.rename(columns={'pessimistic_wheelspinning': 'is_wheelspinning'}, inplace=True)\n",
    "no_indeterminate_df.drop(columns='optimistic_wheelspinning', inplace=True)\n",
    "no_indeterminate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7958773",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(processed_df))\n",
    "print(len(no_indeterminate_df))\n",
    "\n",
    "len(no_indeterminate_df.groupby(['user_id', 'skill_id']).count()) / len(processed_df.groupby(['user_id', 'skill_id']).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f26b56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((no_indeterminate_df.user_id.nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d0fcca-686e-47a3-8567-c3f92db187d4",
   "metadata": {
    "id": "76d0fcca-686e-47a3-8567-c3f92db187d4"
   },
   "source": [
    "*Your discussion about your processing decisions goes here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85633adb-d317-4ee3-bf06-e9f82f589c41",
   "metadata": {
    "id": "85633adb-d317-4ee3-bf06-e9f82f589c41"
   },
   "source": [
    "## Task 2: Model Building\n",
    "\n",
    "Train a model for your research question. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b65ebd-c148-4ae8-833e-018411eeda86",
   "metadata": {
    "id": "90b65ebd-c148-4ae8-833e-018411eeda86"
   },
   "outputs": [],
   "source": [
    "# Your code for training a model goes here\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_auc_score, balanced_accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler, normalize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# label_df = pd.DataFrame(no_indeterminate_df.groupby(['user_id','skill_id'])['is_wheelspinning'].unique())\n",
    "# label_df['is_wheelspinning'] = label_df.apply(\n",
    "#     lambda row: row.is_wheelspinning[0],\n",
    "#     axis=1\n",
    "# )\n",
    "# training_df = no_indeterminate_df.drop(columns=['is_wheelspinning'])\n",
    "training_df = no_indeterminate_df.copy()\n",
    "datasets = {}\n",
    "models = {}\n",
    "results = {}\n",
    "\n",
    "def compute_scores(clf, X_train, y_train, X_test, y_test, roundnum=3):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "    y_pred_proba = clf.predict_proba(X_test)[:,1]\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    return round(accuracy, roundnum), round(auc, roundnum)\n",
    "\n",
    "\n",
    "\n",
    "for po in range(2, PO_CUTOFF+1):\n",
    "    dataset = training_df[no_indeterminate_df.po < po]\n",
    "    users = dataset.user_id.unique()\n",
    "    users_train, users_val = train_test_split(users, test_size=0.2, random_state=0)\n",
    "    \n",
    "    X_train = dataset[dataset.user_id.isin(users_train)]\n",
    "    X_val = dataset[dataset.user_id.isin(users_val)]\n",
    "    y_train = X_train.is_wheelspinning\n",
    "    X_train.drop(columns='is_wheelspinning', inplace=True)\n",
    "    y_val = X_val.is_wheelspinning\n",
    "    X_val.drop(columns='is_wheelspinning', inplace=True)\n",
    "    datasets[po] = (X_train, X_val, y_train, y_val)\n",
    "    models[po] = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=5,\n",
    "        random_state=0,\n",
    "        criterion='entropy'\n",
    "    )\n",
    "    results[po] = compute_scores(\n",
    "        models[po], X_train, y_train, X_val, y_val\n",
    "    )\n",
    "    print(f'For practice opportunity {po}, balanced accuracy = {results[po][0]}, AUC={results[po][1]}')\n",
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c88994",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import time\n",
    "dir_name = time.time()\n",
    "os.mkdir(f'./models/{dir_name}_{PO_CUTOFF}')\n",
    "for po in range(2, PO_CUTOFF):\n",
    "    os.mkdir(f'./models/{dir_name}_{PO_CUTOFF}/datasets_{po}')\n",
    "    pickle.dump(datasets[po][0], open(f'./models/{dir_name}_{PO_CUTOFF}/datasets_{po}/x_train.pkl', 'wb'))\n",
    "    pickle.dump(datasets[po][1], open(f'./models/{dir_name}_{PO_CUTOFF}/datasets_{po}/x_val.pkl', 'wb'))\n",
    "    pickle.dump(datasets[po][2], open(f'./models/{dir_name}_{PO_CUTOFF}/datasets_{po}/y_train.pkl', 'wb'))\n",
    "    pickle.dump(datasets[po][3], open(f'./models/{dir_name}_{PO_CUTOFF}/datasets_{po}/y_val.pkl', 'wb'))\n",
    "    pickle.dump(models[po], open(f'./models/{dir_name}_{PO_CUTOFF}/model_{po}.pkl', 'wb'))\n",
    "pickle.dump(results, open(f'./models/{dir_name}_{PO_CUTOFF}/results.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9dd126",
   "metadata": {},
   "source": [
    "*Your discussion about your model training goes here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c9a655-cec9-4c57-aec7-7a982f57a3af",
   "metadata": {
    "id": "b3c9a655-cec9-4c57-aec7-7a982f57a3af"
   },
   "source": [
    "## Task 3: Model Evaluation\n",
    "In this task, you will use metrics to evaluate your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01e838f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for model evaluation goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57e3f3d",
   "metadata": {},
   "source": [
    "*Your discussion/interpretation about your model's behavior goes here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1607d4b3",
   "metadata": {},
   "source": [
    "## Task 4: Team Reflection\n",
    "Please describe the contributions of each team member to Milestone 4. Reflect on how you worked as team: what went well, what can be improved for the next milestone?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3dd783",
   "metadata": {},
   "source": [
    "*Your discussion about team responsibilities goes here*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "m2-classtime-sciper.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "5ae935d15d48ebdb97660a605eaaed321c4390766b1d9f8f679a61125f89d14f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
